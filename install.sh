#!/bin/bash
# Unified Installation Script for Instagram Reels Transcriber
# One script to install everything including Python if needed

echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘                                                                  â•‘"
echo "â•‘     Instagram Reels Transcriber - Complete Installation         â•‘"
echo "â•‘                                                                  â•‘"
echo "â•‘     One command to install EVERYTHING you need!                 â•‘"
echo "â•‘                                                                  â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo

# Detect OS
detect_os() {
    if [[ "$OSTYPE" == "darwin"* ]]; then
        echo "macOS"
    elif [[ "$OSTYPE" == "linux-gnu"* ]]; then
        echo "linux"
    elif [[ "$OSTYPE" == "msys" ]] || [[ "$OSTYPE" == "cygwin" ]]; then
        echo "windows"
    else
        echo "unknown"
    fi
}

OS_TYPE=$(detect_os)
echo "ğŸ” Detected OS: $OS_TYPE"
echo

# Step 1: Check/Install Python 3.12
echo "ğŸ“¦ Step 1: Python 3.12"
echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
if ! command -v python3.12 &> /dev/null; then
    echo "âš ï¸  Python 3.12 not found. Installing..."

    case $OS_TYPE in
        macOS)
            # Install Homebrew if needed
            if ! command -v brew &> /dev/null; then
                echo "Installing Homebrew..."
                /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
            fi
            echo "Installing Python 3.12 via Homebrew..."
            brew install python@3.12
            brew install python-tk@3.12  # For GUI support
            ;;
        linux)
            if command -v apt-get &> /dev/null; then
                echo "Installing Python 3.12 via apt..."
                sudo apt-get update
                sudo apt-get install -y python3.12 python3.12-venv python3.12-tk
            elif command -v yum &> /dev/null; then
                echo "Installing Python 3.12 via yum..."
                sudo yum install -y python312 python312-tkinter
            else
                echo "âŒ Unsupported Linux distribution"
                echo "Please install Python 3.12 manually"
                exit 1
            fi
            ;;
        windows)
            echo "Windows detected. Please install Python 3.12 from:"
            echo "https://www.python.org/downloads/"
            exit 1
            ;;
        *)
            echo "âŒ Unknown OS. Please install Python 3.12 manually"
            exit 1
            ;;
    esac

    # Verify installation
    if ! command -v python3.12 &> /dev/null; then
        echo "âŒ Python 3.12 installation failed"
        exit 1
    fi
fi
echo "âœ… Python 3.12: $(python3.12 --version)"
echo

# Step 2: Install uv package manager
echo "ğŸ“¦ Step 2: UV Package Manager"
echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
if ! command -v uv &> /dev/null; then
    echo "Installing uv..."
    curl -LsSf https://astral.sh/uv/install.sh | sh

    # Source shell config to get uv in PATH
    if [ -f "$HOME/.bashrc" ]; then
        source "$HOME/.bashrc"
    elif [ -f "$HOME/.zshrc" ]; then
        source "$HOME/.zshrc"
    fi

    # Add to PATH for current session
    export PATH="$HOME/.cargo/bin:$PATH"

    if ! command -v uv &> /dev/null; then
        echo "âš ï¸  uv installed but not in PATH. Please run:"
        echo "  export PATH=\"\$HOME/.cargo/bin:\$PATH\""
        echo "  Then re-run this script"
        exit 1
    fi
fi
echo "âœ… uv: $(uv --version)"
echo

# Step 3: Create virtual environment
echo "ğŸ“¦ Step 3: Virtual Environment"
echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
if [ -d ".venv" ]; then
    echo "Removing old virtual environment..."
    rm -rf .venv
fi
echo "Creating new virtual environment with Python 3.12..."
uv venv --python python3.12
echo "âœ… Virtual environment created"
echo

# Step 4: Install dependencies
echo "ğŸ“¦ Step 4: Python Dependencies"
echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
echo "Installing all required packages..."

# Create comprehensive requirements file if it doesn't exist
cat > requirements_complete.txt << 'EOF'
# Core functionality
FreeSimpleGUI==5.2.0
instaloader==4.14.2
yt-dlp>=2024.1.0
moviepy==1.0.3
faster-whisper>=1.2.0

# AI Models
openai-whisper>=20230918

# Audio processing
numpy>=1.26.0
scipy>=1.14.0

# System utilities
psutil==5.9.5
requests>=2.32.0
urllib3>=2.0.0

# Logging and configuration
python-dotenv==1.0.0

# Testing
pytest-benchmark>=4.0.0

# UI
rich>=13.0.0
EOF

source .venv/bin/activate
uv pip install -r requirements_complete.txt

if [ $? -eq 0 ]; then
    echo "âœ… All dependencies installed successfully"
else
    echo "âš ï¸  Some dependencies failed to install"
fi
echo

# Step 5: Whisper AI Model Selection
echo "ğŸ“¦ Step 5: Whisper AI Model"
echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"

# Model selection - Interactive menu (in bash, not Python)
echo
echo "============================================================"
echo "ğŸ§  Choose Whisper AI Model Size"
echo "============================================================"
echo "Different model sizes offer different trade-offs between speed, accuracy, and disk space:"
echo
echo "1. ğŸš€ Tiny    (39MB)   - Fastest, good for testing"
echo "2. âš¡ Base    (74MB)   - Good balance (recommended)"
echo "3. ğŸ“ˆ Small   (244MB)  - Better accuracy, slower"
echo "4. ğŸ¯ Medium  (769MB)  - High accuracy, much slower"
echo "5. ğŸ† Large   (1550MB) - Best accuracy, very slow"
echo
echo "ğŸ’¡ Recommendation: Choose 'Base' for most users, 'Large' for best quality"
echo "============================================================"

# Check if we should force non-interactive mode (for CI/CD environments)
if [[ "${CI}" == "true" ]] || [[ "${GITHUB_ACTIONS}" == "true" ]] || [[ "${GITLAB_CI}" == "true" ]] || [[ -n "${JENKINS_URL}" ]] || [[ "${BUILDKITE}" == "true" ]] || [[ "${CIRCLECI}" == "true" ]] || [[ -n "${WHISPER_MODEL_AUTO}" ]]; then
    # Auto-select model for CI/CD
    MODEL_SIZE="${WHISPER_MODEL_AUTO:-base}"
    echo "ğŸ¤– CI/CD environment detected - using $MODEL_SIZE model"
    echo "ğŸ’¡ Set WHISPER_MODEL_AUTO=tiny|base|small|medium|large to choose different model"
else
    # Interactive mode: show menu and get user choice
    echo "ğŸ“ Please make your selection..."
    read -p "Enter your choice (1-5) [default: 2 for Base]: " choice

    # Default to base if nothing entered
    if [[ -z "$choice" ]]; then
        choice="2"
    fi

    case $choice in
        1)
            MODEL_SIZE="tiny"
            echo "âœ… Selected: Tiny model (39MB) - Fast processing"
            ;;
        2)
            MODEL_SIZE="base"
            echo "âœ… Selected: Base model (74MB) - Recommended balance"
            ;;
        3)
            MODEL_SIZE="small"
            echo "âœ… Selected: Small model (244MB) - Better accuracy"
            ;;
        4)
            MODEL_SIZE="medium"
            echo "âœ… Selected: Medium model (769MB) - High accuracy"
            ;;
        5)
            MODEL_SIZE="large"
            echo "âœ… Selected: Large model (1550MB) - Best accuracy"
            ;;
        *)
            echo "âŒ Invalid choice, using default Base model"
            MODEL_SIZE="base"
            ;;
    esac
fi

echo
echo "ğŸ¯ Will download $MODEL_SIZE model"

# Save model selection to configuration file
cat > config.json << EOF
{
  "whisper_model": "$MODEL_SIZE"
}
EOF
echo "ğŸ’¾ Saved model selection to config.json"
echo

python3.12 << PYTHON_SCRIPT
import urllib.request
import hashlib
from pathlib import Path
import sys
import time
import os

# Get MODEL_SIZE from environment (set by bash script above)
MODEL_SIZE = "$MODEL_SIZE"

# Define MODELS dictionary
MODELS = {
    'tiny': {
        'url': 'https://openaipublic.azureedge.net/main/whisper/models/65147644a518d12f04e32d6f3b26facc3f8dd46e5390956a9424a650c0ce22b9/tiny.pt',
        'size_mb': 39,
        'sha256': '65147644a518d12f04e32d6f3b26facc3f8dd46e5390956a9424a650c0ce22b9'
    },
    'base': {
        'url': 'https://openaipublic.azureedge.net/main/whisper/models/ed3a0b6b1c0edf879ad9b11b1af5a0e6ab5db9205f891f668f8b0e6c6326e34e/base.pt',
        'size_mb': 74,
        'sha256': 'ed3a0b6b1c0edf879ad9b11b1af5a0e6ab5db9205f891f668f8b0e6c6326e34e'
    },
    'small': {
        'url': 'https://openaipublic.azureedge.net/main/whisper/models/9ecf779972d90ba49c06d968637d720dd632c55bbf19d441fb42bf17a411e794/small.pt',
        'size_mb': 244,
        'sha256': '9ecf779972d90ba49c06d968637d720dd632c55bbf19d441fb42bf17a411e794'
    },
    'medium': {
        'url': 'https://openaipublic.azureedge.net/main/whisper/models/345ae4da62f9b3d59415adc60127b97c714f32e89e936602e85993674d08dcb1/medium.pt',
        'size_mb': 769,
        'sha256': '345ae4da62f9b3d59415adc60127b97c714f32e89e936602e85993674d08dcb1'
    },
    'large': {
        'url': 'https://openaipublic.azureedge.net/main/whisper/models/81f7c96c852ee8fc832187b0132e569d6c3065a3252ed18e56effd0b6884409c/large-v2.pt',
        'size_mb': 1550,
        'sha256': '81f7c96c852ee8fc832187b0132e569d6c3065a3252ed18e56effd0b6884409c'
    }
}

print(f"ğŸ“¥ Downloading {MODEL_SIZE} model ({MODELS[MODEL_SIZE]['size_mb']}MB)...")

model_info = MODELS[MODEL_SIZE]

# Determine cache directory
import os
if os.name == 'nt':  # Windows
    cache_dir = Path.home() / 'AppData' / 'Local' / 'whisper'
else:  # macOS/Linux
    cache_dir = Path.home() / '.cache' / 'whisper'

cache_dir.mkdir(parents=True, exist_ok=True)
model_path = cache_dir / f'{MODEL_SIZE}.pt'

# Check if already downloaded
if model_path.exists():
    print(f"âœ… Model '{MODEL_SIZE}' already exists at {model_path}")
    # Verify checksum
    sha256_hash = hashlib.sha256()
    with open(model_path, 'rb') as f:
        for chunk in iter(lambda: f.read(8192), b''):
            sha256_hash.update(chunk)

    if sha256_hash.hexdigest() == model_info['sha256']:
        print("âœ… Model verified successfully")
        sys.exit(0)
    else:
        print("âš ï¸  Model corrupted, re-downloading...")

# Download the model
print(f"Downloading {MODEL_SIZE} model ({model_info['size_mb']}MB)...")
temp_path = model_path.with_suffix('.download')

def download_with_progress(url, dest):
    response = urllib.request.urlopen(url)
    total_size = int(response.headers.get('Content-Length', 0))
    downloaded = 0
    block_size = 8192

    with open(dest, 'wb') as f:
        while True:
            buffer = response.read(block_size)
            if not buffer:
                break
            downloaded += len(buffer)
            f.write(buffer)

            # Show progress
            if total_size > 0:
                percent = (downloaded / total_size) * 100
                print(f"\rProgress: {percent:.1f}% ({downloaded/1024/1024:.1f}/{total_size/1024/1024:.1f}MB)", end='', flush=True)
    print()  # New line after progress

try:
    download_with_progress(model_info['url'], temp_path)

    # Verify download
    sha256_hash = hashlib.sha256()
    with open(temp_path, 'rb') as f:
        for chunk in iter(lambda: f.read(8192), b''):
            sha256_hash.update(chunk)

    if sha256_hash.hexdigest() == model_info['sha256']:
        temp_path.rename(model_path)
        print(f"âœ… Model downloaded and verified successfully")
    else:
        temp_path.unlink(missing_ok=True)
        print("âŒ Model verification failed")
        sys.exit(1)

except Exception as e:
    print(f"âŒ Download failed: {e}")
    if temp_path.exists():
        temp_path.unlink(missing_ok=True)
    sys.exit(1)
PYTHON_SCRIPT
echo

# Step 6: Test installation
echo "ğŸ“¦ Step 6: Testing Installation"
echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
source .venv/bin/activate
python -c "
import sys
errors = []

try:
    import whisper
    print('âœ… Whisper AI model')
except ImportError as e:
    errors.append(f'âŒ Whisper: {e}')

try:
    import FreeSimpleGUI
    print('âœ… GUI framework')
except ImportError as e:
    errors.append(f'âš ï¸  GUI framework (tkinter may be missing): {e}')

try:
    import yt_dlp
    print('âœ… YouTube downloader')
except ImportError as e:
    errors.append(f'âŒ YouTube downloader: {e}')

try:
    import moviepy
    print('âœ… Video processing')
except ImportError as e:
    errors.append(f'âŒ Video processing: {e}')

try:
    import faster_whisper
    print('âœ… Faster Whisper')
except ImportError as e:
    errors.append(f'âŒ Faster Whisper: {e}')

if errors:
    print()
    for error in errors:
        print(error)
    sys.exit(1)
"

if [ $? -eq 0 ]; then
    echo
    echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    echo "â•‘                                                                  â•‘"
    echo "â•‘     ğŸ‰ Installation Complete! ğŸ‰                                â•‘"
    echo "â•‘                                                                  â•‘"
    echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo
    echo "ğŸ“š Next Steps:"
    echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
    echo
    echo "1. Activate the virtual environment:"
    echo "   source .venv/bin/activate"
    echo
    echo "2. Run the application:"
    echo "   â€¢ GUI Mode: python main.py"
    echo "   â€¢ CLI Mode: python cli.py --help"
    echo
    echo "3. Quick test with a URL:"
    echo "   python cli.py --url 'YOUR_INSTAGRAM_REEL_URL'"
    echo
    echo "Enjoy transcribing your Instagram Reels! ğŸ¬"
else
    echo
    echo "âš ï¸  Installation completed with some warnings"
    echo "The application may still work, but some features might be limited"
fi
